<!-- HTML header for doxygen 1.8.18-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Streaming plugin documentation</title>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.9.2/umd/popper.min.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/5.3.2/cerulean/bootstrap.min.css" rel="stylesheet">
<link href="css/demo.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/5.3.2/js/bootstrap.min.js"></script>
<script type="text/javascript" src="doxy-boot.js"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<a href="https://github.com/meetecho/janus-gateway"><img style="position: absolute; top: 0; left: 0; border: 0; z-index: 2001;" src="forkme_left_darkblue_121621.png" alt="Fork me on GitHub"></a>
<div class="navbar navbar-expand-lg fixed-top navbar-dark bg-primary">
<div class="container">
	<a class="navbar-brand" href="/">Janus (multistream)</a>
	<button type="button" class="navbar-toggler" data-toggle="collapse" data-target=".navbar-collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false">
		<span class="navbar-toggler-icon"></span>
	</button>
	<div class="navbar-collapse collapse" id="navbarResponsive">
		<ul class="navbar-nav">
			<li class="nav-item"><a class="nav-link" href="/">Home</a></li>
			<li class="nav-item"><a class="nav-link" href="/demos/">Demos</a></li>
			<li class="nav-item"><a class="nav-link active" href="index.html">Documentation</a></li>
			<li class="nav-item"><a class="nav-link" href="/citeus.html">Papers</a></li>
			<li class="nav-item"><a class="nav-link" href="/support.html">Need help?</a></li>
			<li class="nav-item"><a class="nav-link" href="https://janus-legacy.conf.meetecho.com/">Janus (0.x)</a></li>
			<li class="nav-item"><a class="nav-link januscon" target="_blank" href="https://januscon.it">JanusCon!</a></li>
		</ul>
		<ul class="navbar-nav ms-auto">
			<li class="nav-item">
				<a class="nav-link meetecho-logo" target="_blank" href="https://www.meetecho.com">
					<img src="meetecho-logo.png"/>
				</a>
			</li>
		</ul>
	</div>
</div>
</div>
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="topics.html"><span>Topics</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">Streaming plugin documentation</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This is a streaming plugin for Janus, allowing WebRTC peers to watch/listen to pre-recorded files or media generated by another tool. Specifically, the plugin currently supports three different type of streams:</p>
<ol type="1">
<li>on-demand streaming of pre-recorded media files (different streaming context for each peer);</li>
<li>live streaming of pre-recorded media files (shared streaming context for all peers attached to the stream);</li>
<li>live streaming of media generated by another tool (shared streaming context for all peers attached to the stream).</li>
</ol>
<p>For what concerns types 1. and 2., considering the proof of concept nature of the implementation the only pre-recorded media files that the plugins supports right now are Opus, raw mu-Law and a-Law files: support is of course planned for other additional widespread formats as well.</p>
<p>For what concerns type 3., instead, the plugin is configured to listen on a few ports for RTP: this means that the plugin is implemented to receive RTP on those ports and relay them to all peers attached to that stream. Any tool that can generate audio/video RTP streams and specify a destination is good for the purpose: the examples section contains samples that make use of GStreamer (<a href="http://gstreamer.freedesktop.org/">http://gstreamer.freedesktop.org/</a>) but other tools like FFmpeg (<a href="http://www.ffmpeg.org/">http://www.ffmpeg.org/</a>), LibAV (<a href="http://libav.org/">http://libav.org/</a>) or others are fine as well. This makes it really easy to capture and encode whatever you want using your favourite tool, and then have it transparently broadcasted via WebRTC using Janus. Notice that we recently added the possibility to also add a datachannel track to an RTP streaming mountpoint: this allows you to send, via UDP, a text-based message to relay via datachannels (e.g., the title of the current song, if this is a radio streaming channel). When using this feature, though, beware that you'll have to stay within the boundaries of the MTU, as each message will have to stay within the size of an UDP packet.</p>
<p>Streams to make available are listed in the plugin configuration file. A pre-filled configuration file is provided in <code>conf/janus.plugin.streaming.jcfg</code> and includes some examples you can start from.</p>
<p>To add more streams or modify the existing ones, you can use the following syntax:</p>
<pre class="fragment">stream-name: {
        [settings]
}
</pre><p>with the allowed settings listed below:</p>
<pre class="fragment">type = rtp|live|ondemand|rtsp
       rtp = stream originated by an external tool (e.g., gstreamer or
             ffmpeg) and sent to the plugin via RTP
       live = local file streamed live to multiple viewers
              (multiple viewers = same streaming context)
       ondemand = local file streamed on-demand to a single listener
                  (multiple viewers = different streaming contexts)
       rtsp = stream originated by an external RTSP feed (only
              available if libcurl support was compiled)
id = &lt;unique numeric ID&gt;
description = This is my awesome stream
metadata = An optional string that can contain any metadata (e.g., JSON)
                        associated with the stream you want users to receive
is_private = true|false (private streams don't appear when you do a 'list' request)
filename = path to the local file to stream (only for live/ondemand)
secret = &lt;optional password needed for manipulating (e.g., destroying
                or enabling/disabling) the stream&gt;
pin = &lt;optional password needed for watching the stream&gt;
audio = true|false (do/don't stream audio)
video = true|false (do/don't stream video)
   The following options are only valid for the 'rtp' type:
data = true|false (do/don't stream text via datachannels)
audioport = local port for receiving audio frames
audiortcpport = local port for receiving and sending audio RTCP feedback
audiomcast = multicast group for receiving audio frames, if any
audioiface = network interface or IP address to bind to, if any (binds to all otherwise)
audiopt = &lt;audio RTP payload type&gt; (e.g., 111)
audiocodec = name of the audio codec (opus)
audiofmtp = Codec specific parameters, if any
audioskew = true|false (whether the plugin should perform skew
        analysis and compensation on incoming audio RTP stream, EXPERIMENTAL)
videoport = local port for receiving video frames (only for rtp)
videortcpport = local port for receiving and sending video RTCP feedback
videomcast = multicast group for receiving video frames, if any
videoiface = network interface or IP address to bind to, if any (binds to all otherwise)
videopt = &lt;video RTP payload type&gt; (e.g., 100)
videocodec = name of the video codec (vp8)
videofmtp = Codec specific parameters, if any
videobufferkf = true|false (whether the plugin should store the latest
        keyframe and send it immediately for new viewers, EXPERIMENTAL)
videosimulcast = true|false (do|don't enable video simulcasting)
videoport2 = second local port for receiving video frames (only for rtp, and simulcasting)
videoport3 = third local port for receiving video frames (only for rtp, and simulcasting)
videoskew = true|false (whether the plugin should perform skew
        analysis and compensation on incoming video RTP stream, EXPERIMENTAL)
videosvc = true|false (whether the video will have SVC support; works only for VP9-SVC, default=false)
h264sps = if using H.264 as a video codec, value of the sprop-parameter-sets
        that would normally be sent via SDP, but that we'll use to instead
        manually ingest SPS and PPS packets via RTP for streams that miss it
collision = in case of collision (more than one SSRC hitting the same port), the plugin
        will discard incoming RTP packets with a new SSRC unless this many milliseconds
        passed, which would then change the current SSRC (0=disabled)
dataport = local port for receiving data messages to relay
datamcast = multicast group for receiving data messages, if any
dataiface = network interface or IP address to bind to, if any (binds to all otherwise)
datatype = text|binary (type of data this mountpoint will relay, default=text)
databuffermsg = true|false (whether the plugin should store the latest
        message and send it immediately for new viewers)
threads = number of threads to assist with the relaying part, which can help
        if you expect a lot of viewers that may cause the RTP receiving part
        in the Streaming plugin to slow down and fail to catch up (default=0)

In case you want to use SRTP for your RTP-based mountpoint, you'll need
to configure the SRTP-related properties as well, namely the suite to
use for hashing (32 or 80) and the crypto information for decrypting
the stream (as a base64 encoded string the way SDES does it). Notice
that with SRTP involved you'll have to pay extra attention to what you
feed the mountpoint, as you may risk getting SRTP decrypt errors:
srtpsuite = 32
srtpcrypto = WbTBosdVUZqEb6Htqhn+m3z7wUh4RJVR8nE15GbN

The Streaming plugin can also be used to (re)stream media that has been
encrypted using something that can be consumed via Insertable Streams.
In that case, we only need to be aware of it, so that we can send the
info along with the SDP. How to decrypt the media is out of scope, and
up to the application since, again, this is end-to-end encryption and
so neither Janus nor the Streaming plugin have access to anything.
DO NOT SET THIS PROPERTY IF YOU DON'T KNOW WHAT YOU'RE DOING!
e2ee = true

To allow mountpoints to negotiate the playout-delay RTP extension,
you can set the 'playoutdelay_ext' property to true: this way, any
subscriber can customize the playout delay of incoming video streams,
assuming the browser supports the RTP extension in the first place.
playoutdelay_ext = true

To allow mountpoints to negotiate the abs-capture-time RTP extension,
you can set the 'abscapturetime_src_ext_id' property to value in range 1..14 inclusive: this way, any
subscriber can receive the abs-capture-time of incoming RTP streams,
assuming the browser supports the RTP extension in the first place.
Incoming RTP stream should provide abs-capture-time exactly in the same header id.
abscapturetime_src_ext_id = 1

The following options are only valid for the 'rtsp' type:
url = RTSP stream URL
rtsp_user = RTSP authorization username, if needed
rtsp_pwd = RTSP authorization password, if needed
rtsp_quirk = Some RTSP servers offer the stream using only the path, instead of the fully qualified URL.
        If set true, this boolean informs Janus that we should try a path-only DESCRIBE request if the initial request returns 404.
rtsp_failcheck = whether an error should be returned if connecting to the RTSP server fails (default=true)
rtspiface = network interface IP address or device name to listen on when receiving RTSP streams
rtsp_reconnect_delay = after n seconds passed and no media assumed, the RTSP server has gone and schedule a reconnect (default=5s)
rtsp_session_timeout = by default the streaming plugin will check the RTSP connection with an OPTIONS query,
        the value of the timeout comes from the RTSP session initializer and by default
        this session timeout is the half of this value In some cases this value can be too high (for example more than one minute)
        because of the media server. In that case this plugin will calculate the timeout with this
        formula: timeout = min(session_timeout, rtsp_session_timeout / 2). (default=0s)
rtsp_timeout = communication timeout (CURLOPT_TIMEOUT) for cURL call gathering the RTSP information (default=10s)
rtsp_conn_timeout = connection timeout for cURL (CURLOPT_CONNECTTIMEOUT) call gathering the RTSP information (default=5s)
</pre><p>Notice that attributes like <code>audioport</code> or <code>videopt</code> only make sense when you're creating a mountpoint with a single audio and/or video stream, as the plugin in that case assumes that limitation is fine by you. In case you're interested in creating multistream mountpoints, that is mountpoints that can contain more than one audio and/or video stream at the same time, you HAVE to use a different syntax. Specifically, you'll need to use a <code>media</code> array/list, containing the different streams, in the right order, that you want to make available: each stream will then need to contain the related info, e.g., port to bind to, type of media, codec name and so on. An example is provided below:</p>
<pre class="fragment">multistream-test: {
        type = "rtp"
        id = 123
        description = "Multistream test (1 audio, 2 video)"
        media = (
                {
                        type = "audio"
                        mid = "a"
                        label = "Audio stream"
                        port = 5102
                        pt = 111
                        codec = "opus"
                },
                {
                        type = "video"
                        mid = "v1"
                        label = "Video stream #1"
                        port = 5104
                        pt = 100
                        codec = "vp8"
                },
                {
                        type = "video"
                        mid = "v2"
                        label = "Video stream #2"
                        port = 5106
                        pt = 100
                        codec = "vp8"
                }
        )
}
</pre><p>In the above example, we're creating a mountpoint with a single audio stream and two different video streams: each stream has a unique <code>mid</code> (that you MUST provide) which is what will be used for the SDP offer to send to viewers, and their unique configuration properties. As you can see, it's much cleaner in the way you create and configure mountpoints: there's no hardcoded audio/video prefix for the name of properties, you configure media streams the same way and just add them to a list. Notice that of course this also works with the simple one audio/one video mountpoints you've used so far, and that has been documented before: as such, you're encouraged to start using this new approach as soon as possible, since in the next versions we might deprecate the old one.</p>
<h1><a class="anchor" id="streamapi"></a>
Streaming API</h1>
<p>The Streaming API supports several requests, some of which are synchronous and some asynchronous. There are some situations, though, (invalid JSON, invalid request) which will always result in a synchronous error response even for asynchronous requests.</p>
<p><code>list</code> , <code>info</code> , <code>create</code> , <code>destroy</code> , <code>recording</code> , <code>edit</code> , <code>enable</code> and <code>disable</code> are synchronous requests, which means you'll get a response directly within the context of the transaction. <code>list</code> lists all the available streams; <code>create</code> allows you to create a new mountpoint dynamically, as an alternative to using the configuration file; <code>destroy</code> removes a mountpoint and destroys it; <code>recording</code> instructs the plugin on whether or not a live RTP stream should be recorded while it's broadcasted; <code>enable</code> and <code>disable</code> respectively enable and disable a mountpoint, that is decide whether or not a mountpoint should be available to users without destroying it. <code>edit</code> allows you to dynamically edit some mountpoint properties (e.g., the PIN);</p>
<p>The <code>watch</code> , <code>start</code> , <code>configure</code> , <code>pause</code> , <code>switch</code> and <code>stop</code> requests instead are all asynchronous, which means you'll get a notification about their success or failure in an event. <code>watch</code> asks the plugin to prepare the playout of one of the available streams; <code>start</code> starts the actual playout; <code>pause</code> allows you to pause a playout without tearing down the PeerConnection; <code>switch</code> allows you to switch to a different mountpoint of the same kind (note: only live RTP mountpoints supported as of now) without having to stop and watch the new one; <code>stop</code> stops the playout and tears the PeerConnection down.</p>
<p>Notice that, in general, all users can create mountpoints, no matter what type they are. If you want to limit this functionality, you can configure an admin <code>admin_key</code> in the plugin settings. When configured, only "create" requests that include the correct <code>admin_key</code> value in an "admin_key" property will succeed, and will be rejected otherwise.</p>
<h2><a class="anchor" id="streamingsync"></a>
Synchronous requests</h2>
<p>To list the available Streaming mountpoints (both those created via configuration file and those created via API), you can use the <code>list</code> request:</p>
<pre class="fragment">{
        "request" : "list"
}
</pre><p>If successful, it will return an array with a list of all the mountpoints. Notice that only the public mountpoints will be returned: those with an <code>is_private</code> set to yes/true will be skipped. The response will be formatted like this:</p>
<pre class="fragment">{
        "streaming" : "list",
        "list" : [
                {
                        "id" : &lt;unique ID of mountpoint #1&gt;,
                        "type" : "&lt;type of mountpoint #1, in line with the types introduced above&gt;",
                        "description" : "&lt;description of mountpoint #1&gt;",
                        "metadata" : "&lt;metadata of mountpoint #1, if any&gt;",
                        "enabled" : &lt;true|false, depending on whether the mountpoint is currently enabled or not&gt;,
                        "media" : [
                                {
                                        "mid" : "&lt;unique mid of this stream&gt;",
                                        "label" : "&lt;unique text label of this stream&gt;",
                                        "msid" : "&lt;msid of this stream, if configured&gt;",
                                        "type" : "&lt;audio|video|data"&gt;,
                                        "age_ms" : &lt;how much time passed since we last received media for this stream; optional&gt;,
                                },
                                {
                                        // Other streams, if available
                                }
                        ]
                },
                {
                        "id" : &lt;unique ID of mountpoint #2&gt;,
                        "type" : "&lt;type of mountpoint #2, in line with the types introduced above&gt;",
                        "description" : "&lt;description of mountpoint #2&gt;",
                        "metadata" : "&lt;metadata of mountpoint #2, if any&gt;",
                        "media" : [..]
                },
                ...
        ]
}
</pre><p>As you can see, the <code>list</code> request only returns very generic info on each mountpoint. In case you're interested in learning more details about a specific mountpoint, you can use the <code>info</code> request instead, which returns more information, or all of it if the mountpoint secret is provided in the request. An <code>info</code> request must be formatted like this:</p>
<pre class="fragment">{
        "request" : "info"
        "id" : &lt;unique ID of mountpoint to query&gt;,
        "secret" : &lt;mountpoint secret; optional, can be used to return more info&gt;"
}
</pre><p>If successful, this will have the plugin return an object containing more info on the mountpoint:</p>
<pre class="fragment">{
        "streaming" : "info",
        "info" : {
                "id" : &lt;unique ID of mountpoint&gt;,
                "name" : "&lt;unique name of mountpoint&gt;",
                "description" : "&lt;description of mountpoint&gt;",
                "metadata" : "&lt;metadata of mountpoint, if any&gt;",
                "secret" : "&lt;secret of mountpoint; only available if a valid secret was provided&gt;",
                "pin" : "&lt;PIN to access mountpoint; only available if a valid secret was provided&gt;",
                "is_private" : &lt;true|false, depending on whether the mountpoint is listable; only available if a valid secret was provided&gt;,
                "viewers" : &lt;count of current subscribers, if any&gt;,
                "enabled" : &lt;true|false, depending on whether the mountpoint is currently enabled or not&gt;,
                "type" : "&lt;type of mountpoint&gt;",
                "media" : [
                        {
                                "mid" : "&lt;unique mid of this stream&gt;",
                                "mindex" : "&lt;unique mindex of this stream&gt;",
                                "type" : "&lt;audio|video|data"&gt;,
                                "label" : "&lt;unique text label of this stream&gt;",
                                "msid" : "&lt;msid of this stream, if configured&gt;",
                                "age_ms" : &lt;how much time passed since we last received media for this stream; optional&gt;,
                                "pt" : &lt;payload type, only present if RTP and configured&gt;,
                                "codec" : "&lt;cocec name value, only present if RTP and configured&gt;",
                                "rtpmap" : "&lt;SDP rtpmap value, only present if RTP and configured&gt;",
                                "fmtp" : "&lt;audio SDP fmtp value, only present if RTP and configured&gt;",
                                ...
                        },
                        {
                                // Other streams, if available
                        }
                ]
        }
}
</pre><p>Considering the different mountpoint types that you can create in this plugin, the nature of the rest of the returned info obviously depends on which mountpoint you're querying. This is especially true for RTP and RTSP mountpoints. Notice that info like the ports an RTP mountpoint is listening on will only be returned if you provide the correct secret, as otherwise they're treated like sensitive information and are not returned to generic <code>info</code> calls.</p>
<p>We've seen how you can create a new mountpoint via configuration file, but you can create one via API as well, using the <code>create</code> request. Most importantly, you can also choose whether or not a <code>create</code> request should result in the mountpoint being saved to configuration file so that it's still available after a server restart. The common syntax for all <code>create</code> requests is the following:</p>
<pre class="fragment">{
        "request" : "create",
        "admin_key" : "&lt;plugin administrator key; mandatory if configured&gt;",
        "type" : "&lt;type of the mountpoint to create; mandatory&gt;",
        "id" : &lt;unique ID to assign the mountpoint; optional, will be chosen by the server if missing&gt;,
        "name" : "&lt;unique name for the mountpoint; optional, will be chosen by the server if missing&gt;",
        "description" : "&lt;description of mountpoint; optional&gt;",
        "metadata" : "&lt;metadata of mountpoint; optional&gt;",
        "secret" : "&lt;secret to query/edit the mountpoint later; optional&gt;",
        "pin" : "&lt;PIN required for viewers to access mountpoint; optional&gt;",
        "is_private" : &lt;true|false, whether the mountpoint should be listable; true by default&gt;,
        "media" : [
                {
                        "type" : "&lt;audio|video|data&gt;",
                        "mid" : "&lt;unique mid to assign to this stream in negotiated PeerConnections&gt;",
                        "msid" : "&lt;msid to add to the m-line, if needed&gt;",
                        "label", "&lt;optional label to name the track&gt;",
                        "mcast", "&lt;multicast group for receiving packets, if any&gt;",
                        "iface", "&lt;network interface or IP address to bind to, if any (binds to all otherwise)&gt;",
                        "port" : &lt;port to bind to, to receive media to relay&gt;",
                        "rtcpport", &lt;port to bind to for receiving and sending audio RTCP feedback, if any&gt;,
                        "pt", &lt;RTP payload type (audio/video only)&gt;,
                        "codec", "&lt;name of the codec that will be used for this track (audio/video only)&gt;",
                        "fmtp", "&lt;codec specific parameters, if any (audio/video only)&gt;",
                        "skew", &lt;true|false (whether the plugin should perform skew
                                analysis and compensation on incoming RTP streams, EXPERIMENTAL)&gt;
                        "simulcast", &lt;true|false (do|don't enable video simulcasting)&gt;,
                        "port2", &lt;second local port for receiving video frames (only for RTP video, and simulcasting)&gt;,
                        "port3", &lt;third local port for receiving video frames (only for RTP video, and simulcasting)&gt;,
                        "svc", &lt;true|false (whether the RTP video will have SVC support; works only for VP9-SVC, default=false)&gt;,
                        "datatype", "&lt;text|binary (type of data this mountpoint will relay, default=text)&gt;",
                        ...
                }.
                ... other streams, if any ...
        ],
        ...
        "permanent" : &lt;true|false, whether the mountpoint should be saved to configuration file or not; false by default&gt;,
        ...
}
</pre><p>Of course, different mountpoint types will have different properties you can specify in a <code>create</code>. Please refer to the documentation on configuration files to see the fields you can pass. The only important difference to highlight is that, unlike in configuration files, you will NOT have to escape semicolons with a trailing slash, in those properties where a semicolon might be needed (e.g., <code>audiofmtp</code> or <code>videofmtp</code> ).</p>
<p>Notice that, just as we introduced the possibility of configuring multistream mountpoints statically with a <code>media</code> array, the same applies when using the API to create them: just add a <code>media</code> JSON array containing the list of streams to create and the related properties as you would do statically (that is, using generic properties like <code>port</code>, <code>fmtp</code>, etc., rather than the hardcoded <code>audioport</code> and the like), and it will work for dynamically created mountpoints as well.</p>
<p>A successful <code>create</code> will result in a <code>created</code> response:</p>
<pre class="fragment">{
        "streaming" : "created",
        "create" : "&lt;unique name of the just created mountpoint&gt;",
        "permanent" : &lt;true|false, depending on whether the mountpoint was saved to configuration file or not&gt;,
        "stream": {
                "id" : &lt;unique ID of the just created mountpoint&gt;,
                "type" : "&lt;type of the just created mountpoint&gt;",
                "description" : "&lt;description of the just created mountpoint&gt;",
                "is_private" : &lt;true|false, depending on whether the new mountpoint is listable&gt;,
                "ports" : [             // Only for RTP mountpoints
                        {
                                "type" : "&lt;audio|video|data&gt;",
                                "mid" : "&lt;unique mid of stream #1&gt;",
                                "msid" : "&lt;msid of this stream, if configured&gt;",
                                "port" : &lt;port the plugin is listening on for this stream's media&gt;
                        },
                        {
                                // Other streams, if available
                        }
                ]
                ...
        }
}
</pre><p>Notice that additional information, namely the ports the mountpoint bound to, will only be added for new RTP mountpoints, otherwise this is all that a <code>created</code> request will contain. If you want to double check everything in your <code>create</code> request went as expected, you may want to issue a followup <code>info</code> request to compare the results.</p>
<p>Once you created a mountpoint, you can modify some (not all) of its properties via an <code>edit</code> request. Namely, you can only modify generic properties like the mountpoint description, the secret, the PIN and whether or not the mountpoint should be listable. All other properties are considered to be immutable. Again, you can choose whether the changes should be permanent, e.g., saved to configuration file, or not. Notice that an <code>edit</code> request requires the right secret to be provided, if the mountpoint has one, or will return an error instead. The <code>edit</code> request must be formatted like this:</p>
<pre class="fragment">{
        "request" : "edit",
        "id" : &lt;unique ID of the mountpoint to edit; mandatory&gt;,
        "secret" : "&lt;secret to edit the mountpoint; mandatory if configured&gt;",
        "new_description" : "&lt;new description for the mountpoint; optional&gt;",
        "new_metadata" : "&lt;new metadata for the mountpoint; optional&gt;",
        "new_secret" : "&lt;new secret for the mountpoint; optional&gt;",
        "new_pin" : "&lt;new PIN for the mountpoint, PIN will be removed if set to an empty string; optional&gt;",
        "new_is_private" : &lt;true|false, depending on whether the mountpoint should be now listable; optional&gt;,
        "permanent" : &lt;true|false, whether the mountpoint should be saved to configuration file or not; false by default&gt;,
        "edited_event" : &lt;true|false, whether an event will be sent to all viewers when metadata is updated; false by default&gt;
}
</pre><p>A successful <code>edit</code> will result in an <code>edited</code> response:</p>
<pre class="fragment">{
        "streaming" : "edited",
        "id" : &lt;unique ID of the just edited mountpoint&gt;,
        "permanent" : &lt;true|false, depending on whether the changes were saved to configuration file or not&gt;
}
</pre><p>In case <code>edited_event</code> was set to <code>true</code> in the request, a successful <code>edit</code> will also result in an <code>edited</code> event sent to all viewers when the metadata has changed:</p>
<pre class="fragment">{
        "streaming" : "edited",
        "id" : &lt;unique ID of the just edited mountpoint&gt;,
        "metadata" : "&lt;updated metadata for the mountpoint&gt;",
}
</pre><p>Just as you can create and edit mountpoints, you can of course also destroy them. Again, this applies to all mountpoints, whether created statically via configuration file or dynamically via API, and the mountpoint destruction can be made permanent in the configuration file as well. A <code>destroy</code> request must be formatted as follows:</p>
<pre class="fragment">{
        "request" : "destroy",
        "id" : &lt;unique ID of the mountpoint to destroy; mandatory&gt;,
        "secret" : "&lt;secret to destroy the mountpoint; mandatory if configured&gt;",
        "permanent" : &lt;true|false, whether the mountpoint should be removed from the configuration file or not; false by default&gt;
}
</pre><p>If successful, the result will be confirmed in a <code>destroyed</code> event:</p>
<pre class="fragment">{
        "streaming" : "destroyed",
        "id" : &lt;unique ID of the just destroyed mountpoint&gt;
}
</pre><p>Notice that destroying a mountpoint while viewers are still subscribed to it will result in all viewers being removed, and their PeerConnection closed as a consequence.</p>
<p>You can also dynamically enable and disable mountpoints via API. A disabled mountpoint is a mountpoint that exists, and still works as expected, but is not accessible to viewers until it's enabled again. This is a useful property, especially in case of mountpoints that need to be prepared in advance but must not be accessible until a specific moment, and a much better alternative to just create the mountpoint at the very last minute and destroy it otherwise. The syntax for both the <code>enable</code> and <code>disable</code> requests is the same, and looks like the following:</p>
<pre class="fragment">{
        "request" : "enable",
        "id" : &lt;unique ID of the mountpoint to enable; mandatory&gt;,
        "secret" : "&lt;secret to enable the mountpoint; mandatory if configured&gt;"
}
</pre><p>If successful, a generic <code>ok</code> is returned:</p>
<pre class="fragment">{
        "streaming" : "ok"
}
</pre> <pre class="fragment">{
        "request" : "disable",
        "id" : &lt;unique ID of the mountpoint to disable; mandatory&gt;,
        "stop_recording" : &lt;true|false, whether the recording should also be stopped or not; true by default&gt;
        "secret" : "&lt;secret to disable the mountpoint; mandatory if configured&gt;"
}
</pre><p>If successful, a generic <code>ok</code> is returned:</p>
<pre class="fragment">{
        "streaming" : "ok"
}
</pre><p>You can kick all viewers from a mountpoint using the <code>kick_all</code> request. Notice that this only removes all viewers, but does not prevent them from starting to watch the mountpoint again. Please note this request works with all mountpoint types, except for on-demand streaming. The <code>kick_all</code> request has to be formatted as follows:</p>
<pre class="fragment">{
        "request" : "kick_all",
        "id" : &lt;unique ID of the mountpoint to disable; mandatory&gt;,
        "secret" : "&lt;mountpoint secret; mandatory if configured&gt;",
}
</pre><p>If successful, a <code>kicked_all</code> response is returned:</p>
<pre class="fragment">{
        "streaming" : "kicked_all",
}
</pre><p>Finally, you can record a mountpoint to the internal Janus .mjr format using the <code>recording</code> request. The same request can also be used to stop recording. Although the same request is used in both cases, though, the syntax for the two use cases differs a bit, namely in terms of the type of some properties. Notice that, while for backwards compatibility you can still use the old <code>audio</code>, <code>video</code> and <code>data</code> named properties, they're now deprecated and so you're highly encouraged to use the new drill-down <code>media</code> list instead.</p>
<p>To start recording a new mountpoint, the request should be formatted like this:</p>
<pre class="fragment">{
        "request" : "recording",
        "action" : "start",
        "id" : &lt;unique ID of the mountpoint to manipulate; mandatory&gt;,
        "media" : [             // Drill-down recording controls
                {
                        "mid" : "&lt;mid of the stream to start recording&gt;",
                        "filename" : "&lt;base path/filename to use for the recording&gt;"
                },
                {
                        // Recording controls for other streams, if provided
                }
        ]
}
</pre><p>To stop a recording, instead, this is the request syntax:</p>
<pre class="fragment">{
        "request" : "recording",
        "action" : "stop",
        "id" : &lt;unique ID of the mountpoint to manipulate; mandatory&gt;,
        "media" : [             // Drill-down recording controls
                {
                        "mid" : "&lt;mid of the stream to stop recording&gt;"
                },
                {
                        // Recording controls for other streams, if provided
                }
        ]
}
</pre><p>When using the deprecated properties, when starting a recording the <code>audio</code> , <code>video</code> and <code>data</code> properties are strings, and specify the base path to use for the recording filename; when stopping a recording, instead, they're interpreted as boolean properties. This is one more reason why you should migrate to the new <code>media</code> list instead, as it doesn't have this ambiguity between the two different requests. Notice that, as with all APIs that wrap .mjr recordings, the filename you specify here is not the actual filename: an <code></code>.mjr extension is always going to be added by the Janus core, so you should take this into account when tracking the related recording files.</p>
<p>Whether you started or stopped a recording, a successful request will always result in a simple <code>ok</code> response:</p>
<pre class="fragment">{
        "streaming" : "ok"
}
</pre><h2><a class="anchor" id="streamingasync"></a>
Asynchronous requests</h2>
<p>All the requests we've gone through so far are synchronous. This means that they return a response right away. That said, many of the requests this plugin supports are asynchronous instead, which means Janus will send an ack when they're received, and a response will only follow later on. This is especially true for requests dealing with the management and setup of mountpoint viewers, e.g., for the purpose of negotiating a WebRTC PeerConnection to receive media from a mountpoint.</p>
<p>To subscribe to a specific mountpoint, an interested viewer can make use of the <code>watch</code> request. As suggested by the request name, this instructs the plugin to setup a new PeerConnection to allow the new viewer to watch the specified mountpoint. The <code>watch</code> request must be formatted like this:</p>
<pre class="fragment">{
        "request" : "watch",
        "id" : &lt;unique ID of the mountpoint to subscribe to; mandatory&gt;,
        "pin" : "&lt;PIN required to access the mountpoint; mandatory if configured&gt;",
        "media" : [
                &lt;array of mids to subscribe to, as strings; optional, missing or empty array subscribes to all mids&gt;
        ]
        "offer_audio" : &lt;true|false; deprecated; whether or not audio should be negotiated; true by default if the mountpoint has audio&gt;,
        "offer_video" : &lt;true|false; deprecated; whether or not video should be negotiated; true by default if the mountpoint has video&gt;,
        "offer_data" : &lt;true|false; deprecated; whether or not datachannels should be negotiated; true by default if the mountpoint has datachannels&gt;
}
</pre><p>As you can see, it's just a matter of specifying the ID of the mountpoint to subscribe to and, if needed, the PIN to access the mountpoint in case it's protected. The <code>media</code> array is particularly interesting, as it allows you to only subscribe to a subset of the mountpoint media, which you can address by the related <code>mid</code> property of each stream. By default, in fact, a <code>watch</code> request will result in the plugin preparing a new SDP offer trying to negotiate all the media streams available in the mountpoint; in case the viewer knows they don't support one of the mountpoint codecs, though (e.g., the video in the mountpoint is VP8, but they only support H.264), or are not interested in getting all the media (e.g., they're ok with just audio and not video, or don't have enough bandwidth for both), they can use those properties to shape the SDP offer to their needs. The <code>media</code> array is optional, as a missing or empty array will simply be interpreted as a willingness to subscribe to all the streams in the mountpoint, which is the default behaviour. Notice that the order of the mids in the <code>media</code> array is irrelevant, as is how many times the same mid is listed in the array: the presence of a mid is just interpreted as an "on" switch for that stream, meaning it will be offered in the SDP.</p>
<dl class="section note"><dt>Note</dt><dd>For backwards compatibility, the deprecated <code>offer_audio</code> , <code>offer_video</code> and <code>offer_data</code> properties are also available. They also allow you to only subscribe to a subset of the mountpoint media, but with a more crude approach: specifically, they dictate whether or not any audio, video or data stream should be offered or not.</dd></dl>
<p>As anticipated, if successful this request will generate a new JSEP SDP offer, which will be attached to a <code>preparing</code> status event:</p>
<pre class="fragment">{
        "status" : "preparing"
}
</pre><p>At this stage, to complete the setup of a subscription the viewer is supposed to send a JSEP SDP answer back to the plugin. This is done by means of a <code>start</code> request, which in this case MUST be associated with a JSEP SDP answer but otherwise requires no arguments:</p>
<pre class="fragment">{
        "request" : "start"
}
</pre><p>If successful this request returns a <code>starting</code> status event:</p>
<pre class="fragment">{
        "status" : "starting"
}
</pre><p>Once this is done, all that's needed is waiting for the WebRTC PeerConnection establishment to succeed. As soon as that happens, the Streaming plugin can start relaying media from the mountpoint the viewer subscribed to to the viewer themselves.</p>
<p>Notice that the same exact steps we just went through (<code>watch</code> request, followed by JSEP offer by the plugin, followed by <code>start</code> request with JSEP answer by the viewer) is what you also use when renegotiations are needed, e.g., for the purpose of ICE restarts.</p>
<p>As a viewer, you can temporarily pause and resume the whole media delivery with a <code>pause</code> and, again, <code>start</code> request (in this case without any JSEP SDP answer attached). Neither expect other arguments, as the context is implicitly derived from the handle they're sent on:</p>
<pre class="fragment">{
        "request" : "pause"
}
</pre><pre class="fragment">{
        "request" : "start"
}
</pre><p>Unsurprisingly, they just result in, respectively, <code>pausing</code> and <code>starting</code> events:</p>
<pre class="fragment">{
        "status" : "pausing"
}
</pre><pre class="fragment">{
        "status" : "starting"
}
</pre><p>For more drill-down manipulations of a subscription, a <code>configure</code> request can be used instead. This request allows viewers to dynamically change some properties associated to their media subscription, e.g., in terms of what should and should not be sent at a specific time. A <code>configure</code> request must be formatted as follows:</p>
<pre class="fragment">{
        "request" : "configure",
        "streams" : [
                {
                        "mid" : &lt;mid of the m-line to tweak&gt;,
                        "send" : &lt;true|false, depending on whether the media addressed by the above mid should be relayed or not; optional&gt;,
                        "substream" : &lt;substream to receive (0-2), in case simulcasting is enabled; optional&gt;,
                        "temporal" : &lt;temporal layers to receive (0-2), in case simulcasting is enabled; optional&gt;,
                        "fallback" : &lt;How much time (in us, default 250000) without receiving packets will make us drop to the substream below&gt;,
                        "spatial_layer" : &lt;spatial layer to receive (0-1), in case VP9-SVC is enabled; optional&gt;,
                        "temporal_layer" : &lt;temporal layers to receive (0-2), in case VP9-SVC is enabled; optional&gt;,
                        "min_delay" : &lt;minimum delay to enforce via the playout-delay RTP extension, in blocks of 10ms; optional&gt;,
                        "max_delay" : &lt;maximum delay to enforce via the playout-delay RTP extension, in blocks of 10ms; optional&gt;
                },
                // Other streams, if any
        ]
}
</pre><p>While the deprecated <code>audio</code> , <code>video</code> and <code>data</code> properties can still be used as a media-level pause/resume functionality, a better option is to specify the <code>mid</code> of the stream instead, and a <code>send</code> boolean property to specify if this specific stream should be relayed or not. The <code>pause</code> and <code>start</code> requests instead pause and resume all streams at the same time. The <code>substream</code> and <code>temporal</code> properties, finally, only make sense when the mountpoint is configured with video simulcasting support, and as such the viewer is interested in receiving a specific substream or temporal layer, rather than any other of the available ones. The <code>spatial_layer</code> and <code>temporal_layer</code> have exactly the same meaning, but within the context of VP9-SVC mountpoints, and will have no effect on mountpoints involving a different video codec. In both cases, make sure you specify the <code>mid</code> of the stream in case multiple videos are available in a mountpoint, or the request may have no effect.</p>
<p>Another interesting feature in the Streaming plugin is the so-called mountpoint "switching". Basically, when subscribed to a specific mountpoint and receiving media from there, you can at any time "switch" to a different mountpoint, and as such start receiving media from that other mountpoint instead. Think of it as changing channel on a TV: you keep on using the same PeerConnection, the plugin simply changes the source of the media transparently. Of course, while powerful and effective this request has some limitations. First of all, it only works with RTP mountpoints, and not other mountpoint types; besides, the two mountpoints must have the same media configuration, that is, use the same codecs, the same payload types, etc. In fact, since the same PeerConnection is used for this feature, switching to a mountpoint with a different configuration might result in media incompatible with the PeerConnection setup being relayed to the viewer, and as such in no audio/video being played. That said, a <code>switch</code> request must be formatted like this:</p>
<pre class="fragment">{
        "request" : "switch",
        "id" : &lt;unique ID of the new mountpoint to switch to; mandatory&gt;
}
</pre><p>If successful, you'll be unsubscribed from the previous mountpoint, and subscribed to the new mountpoint instead. The event to confirm the switch was successful will look like this:</p>
<pre class="fragment">{
        "switched" : "ok",
        "id" : &lt;unique ID of the new mountpoint&gt;
}
</pre><p>Finally, to stop the subscription to the mountpoint and tear down the related PeerConnection, you can use the <code>stop</code> request. Since context is implicit, no other argument is required:</p>
<pre class="fragment">{
        "request" : "stop"
}
</pre><p>If successful, the plugin will attempt to tear down the PeerConnection, and will send back a <code>stopping</code> status event:</p>
<pre class="fragment">{
        "status" : "stopping"
}
</pre><p>Once a PeerConnection has been torn down and the subscription closed, as a viewer you're free to subscribe to a different mountpoint instead. In fact, while you can't watch more than one mountpoint at the same time on the same handle, there's no limit on how many mountpoints you can watch in sequence, again on the same handle. If you're interested in subscribing to multiple mountpoints at the same time, instead, you'll have to create multiple handles for the purpose. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- HTML footer for doxygen 1.8.18-->
<!-- start footer part -->
<div class="footer container">
<hr class="footer"/>
Last updated on Thu Apr 24 2025 &mdash; Janus WebRTC Server &copy; <a target="_blank" href="http://www.meetecho.com/">Meetecho</a> 2014-2025
</div>
</body>
</html>
